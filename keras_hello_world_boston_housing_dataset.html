<!DOCTYPE html>
<html lang="en-US">
    <head>
        <meta charset="utf-8"> 
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <meta name="author" content="Sam Zuckerman" />
        <meta name="copyright" content="Sam Zuckerman" />

<meta name="keywords" content="python, deep learning, keras, neural networks, Keras, " />
        <title>Keras "Hello World" Example for Regression  · programming notes
</title>
        <link href="http://cdn-images.mailchimp.com/embedcode/slim-081711.css" rel="stylesheet" type="text/css">
        <link href="//netdna.bootstrapcdn.com/twitter-bootstrap/2.3.1/css/bootstrap-combined.min.css" rel="stylesheet">
        <link rel="stylesheet" type="text/css" href="/theme/css/style.css" media="screen">
        <link rel="stylesheet" type="text/css" href="/theme/css/solarizedlight.css" media="screen">
        <link rel="shortcut icon" href="/theme/images/favicon.ico" type="image/x-icon" />
        <link rel="apple-touch-icon" href="/theme/images/apple-touch-icon.png" />
        <link rel="apple-touch-icon" sizes="57x57" href="/theme/images/apple-touch-icon-57x57.png" />
        <link rel="apple-touch-icon" sizes="72x72" href="/theme/images/apple-touch-icon-72x72.png" />
        <link rel="apple-touch-icon" sizes="114x114" href="/theme/images/apple-touch-icon-114x114.png" />
        <link rel="apple-touch-icon" sizes="144x144" href="/theme/images/apple-touch-icon-144x144.png" />
        <link rel="icon" href="/theme/images/apple-touch-icon-144x144.png" />
    </head>
    <body>
        <div id="content-sans-footer">
        <div class="navbar navbar-static-top">
            <div class="navbar-inner">
                <div class="container">
                    <a class="btn btn-navbar" data-toggle="collapse" data-target=".nav-collapse">
                        <span class="icon-bar"></span>
                        <span class="icon-bar"></span>
                        <span class="icon-bar"></span>
                    </a>
                    <a class="brand" href="/"><span class=site-name>programming notes</span></a>
                    <div class="nav-collapse collapse">
                        <ul class="nav pull-right top-menu">
                            <!--<li ><a href="">Home</a></li>-->
                            <li ><a href="/categories.html">Categories</a></li>
                            <li ><a href="/tags.html">Tags</a></li>
                            <li ><a href="/archives.html">Archives</a></li>
                            <li><form class="navbar-search" action="/search.html" onsubmit="return validateForm(this.elements['q'].value);"> <input type="text" class="search-query" placeholder="Search" name="q" id="tipue_search_input"></form></li>
                        </ul>
                    </div>
                </div>
            </div>
        </div>
        <div class="container-fluid">
            <div class="row-fluid">
                <div class="span1"></div>
                <div class="span10">
<article>
<div class="row-fluid">
    <header class="page_header span10 offset2">
    <h1><a href="/keras_hello_world_boston_housing_dataset.html"> Keras "Hello World" Example for Regression  </a></h1>
    </header>
</div>

<div class="row-fluid">
        <div class="span8 offset2 article-content">

            <p>The following example uses the <a href="https://www.kaggle.com/c/boston-housing">Boston Housing dataset</a> to predict the median value of homes in a specific Boston suburb in 1978.</p>
<p>We're using this dataset since:
 1. It's well known
 2. It's included in Keras so you don't need to download any other dependencies.</p>
<h1>Getting Keras</h1>
<p>If you don't already have Keras and Scikit-Learn installed, you can download both using pip:</p>
<div class="highlight"><pre><span></span><span class="n">pip</span> <span class="n">install</span> <span class="n">keras</span>
<span class="n">pip</span> <span class="n">install</span> <span class="n">scikit</span><span class="o">-</span><span class="n">learn</span>
</pre></div>


<p>If you need additional help, you can check out <a href="https://keras.io/">the Keras documentation</a>. </p>
<h1>Loading Packages</h1>
<p>We're going to need the following:</p>
<div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">keras.datasets</span> <span class="kn">import</span> <span class="n">boston_housing</span>
<span class="kn">from</span> <span class="nn">keras.models</span> <span class="kn">import</span> <span class="n">Sequential</span>
<span class="kn">from</span> <span class="nn">keras.layers</span> <span class="kn">import</span> <span class="n">Dense</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>

<span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">),</span> <span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span> <span class="o">=</span> <span class="n">boston_housing</span><span class="o">.</span><span class="n">load_data</span><span class="p">()</span>
</pre></div>


<p>Neural networks work best when the data is normalized. The network would get confused with our data when comparing small and big numbers of different units (like tax rates and non-business acres). </p>
<div class="highlight"><pre><span></span><span class="n">scalerX</span> <span class="o">=</span> <span class="n">MinMaxScaler</span><span class="p">(</span><span class="n">feature_range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>
<span class="n">scalerY</span> <span class="o">=</span> <span class="n">MinMaxScaler</span><span class="p">(</span><span class="n">feature_range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>

<span class="n">scaled_training_X</span> <span class="o">=</span> <span class="n">scalerX</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
<span class="n">scaled_testing_X</span> <span class="o">=</span> <span class="n">scalerX</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="n">scaled_training_y</span> <span class="o">=</span> <span class="n">scalerY</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">y_train</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
<span class="n">scaled_testing_y</span> <span class="o">=</span> <span class="n">scalerY</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">y_test</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
</pre></div>


<p>We're going to create a sequential neural network, dense layers and 32 nodes for each layer.</p>
<p>The two important parts in the following code block are <code>input_dim=13</code> and <code>Dense(1, activation='linear')</code>.</p>
<p>The <code>input_dim</code> maps to the number of columns in the dataset (we have 13 variables we're using to predict) and the last layer should have one node (hence, <code>Dense(1)</code>) to show that we're predicting one value.</p>
<div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="n">input_dim</span><span class="o">=</span><span class="mi">13</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;linear&#39;</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s1">&#39;mse&#39;</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="s1">&#39;adam&#39;</span><span class="p">)</span>
</pre></div>


<p>The above model has four layers with two hidden layers where each of the layers are dense. Dense means that every node in one layer maps to every node in the next layer. This way as information passes through the network it will make linear transformations of the data with information of 'lower importance' being pushed closer to zero.</p>
<p>We're basing our loss on MSE or <a href="https://en.wikipedia.org/wiki/Mean_squared_error">Mean Squared Error</a>, a standard regression loss metric (i.e. how 'off' was each prediction from the real value). We're also using the <a href="https://en.wikipedia.org/wiki/Stochastic_gradient_descent#Adam">ADAM optimizer</a> to update the network weights. The more finely tuned the network weights are, the better fit the model will be.</p>
<p>Also, there's discussion as to how many layers and nodes should be included in a network and choosing the right numbers is more of an art than a science. The above could have just as easily been:</p>
<div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="n">input_dim</span><span class="o">=</span><span class="mi">13</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;linear&#39;</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s1">&#39;mse&#39;</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="s1">&#39;adam&#39;</span><span class="p">)</span>
</pre></div>


<p>But with less nodes and layers, we risk underfitting the network.</p>
<h1>Fitting and Evaluating the Model</h1>
<p>Fitting a model in Keras is easy; just run the <code>fit</code> method:</p>
<div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">scaled_training_X</span><span class="p">,</span> <span class="n">scaled_training_y</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>


<p>An epoch is a "run" through the data to optimize the weights. We're choosing 100 epochs since it doesn't take that long to run and we need a good number of passes through the data to allow the optimizer to update the weights accordingly. </p>
<p>Here's the output since we had <code>verbose</code> set to <code>1</code> (showing the first 10 and last 10 epochs):</p>
<div class="highlight"><pre><span></span>Epoch 1/100
404/404 [==============================] - 0s 47us/step - loss: 0.0358
Epoch 2/100
404/404 [==============================] - 0s 48us/step - loss: 0.0188
Epoch 3/100
404/404 [==============================] - 0s 47us/step - loss: 0.0159
Epoch 4/100
404/404 [==============================] - 0s 40us/step - loss: 0.0139
Epoch 5/100
404/404 [==============================] - 0s 43us/step - loss: 0.0125
Epoch 6/100
404/404 [==============================] - 0s 51us/step - loss: 0.0113
Epoch 7/100
404/404 [==============================] - 0s 32us/step - loss: 0.0105
Epoch 8/100
404/404 [==============================] - 0s 40us/step - loss: 0.0099
Epoch 9/100
404/404 [==============================] - 0s 49us/step - loss: 0.0095
Epoch 10/100
404/404 [==============================] - 0s 36us/step - loss: 0.0090
...
Epoch 90/100
404/404 [==============================] - 0s 52us/step - loss: 0.0040
Epoch 91/100
404/404 [==============================] - 0s 48us/step - loss: 0.0041
Epoch 92/100
404/404 [==============================] - 0s 48us/step - loss: 0.0040
Epoch 93/100
404/404 [==============================] - 0s 52us/step - loss: 0.0040
Epoch 94/100
404/404 [==============================] - 0s 31us/step - loss: 0.0040
Epoch 95/100
404/404 [==============================] - 0s 42us/step - loss: 0.0040
Epoch 96/100
404/404 [==============================] - 0s 48us/step - loss: 0.0041
Epoch 97/100
404/404 [==============================] - 0s 38us/step - loss: 0.0040
Epoch 98/100
404/404 [==============================] - 0s 49us/step - loss: 0.0039
Epoch 99/100
404/404 [==============================] - 0s 49us/step - loss: 0.0039
Epoch 100/100
404/404 [==============================] - 0s 34us/step - loss: 0.0039
</pre></div>


<p>And to evaluate:    </p>
<div class="highlight"><pre><span></span><span class="n">mse</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">scaled_testing_X</span><span class="p">,</span> <span class="n">scaled_testing_y</span><span class="p">)</span>
</pre></div>


<p>Since used mse as a loss function above, when we use the <code>evaluate</code> method, we'll get mse returned.</p>
<blockquote>
<p>Note: We are evaluating with the test data and will also be predicting with the test data as well. Usually when preparing a model for production one has a breakdown of training, testing and validation data sets for model evaluation. We are merely using the testing data to show how the model performs on unseen data.  </p>
</blockquote>
<p>Output:</p>
<div class="highlight"><pre><span></span><span class="o">&gt;&gt;&gt;</span><span class="mf">0.16640686755086861</span> 
</pre></div>


<h1>So What Does This Mean?</h1>
<p>Since we have the mse, we want to know how "off" our predictions are. The units are currently (scaled_dollars)^2 which isn't so useful. Therefore we have to 'untransform' it.</p>
<div class="highlight"><pre><span></span><span class="n">result</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">mse</span><span class="p">)</span>
<span class="n">true_result</span> <span class="o">=</span> <span class="n">scalerY</span><span class="o">.</span><span class="n">inverse_transform</span><span class="p">([</span><span class="n">result</span><span class="p">])</span>
</pre></div>


<p>Output:</p>
<div class="highlight"><pre><span></span><span class="n">array</span><span class="p">([[</span> <span class="mf">26.80030564</span><span class="p">]])</span>
</pre></div>


<p><strong>Note:</strong> you might get different slightly results based on rounding issues .</p>
<p>This shows that across all the </p>
<p>def get_results(x):
    pred = model.predict(scaled_testing_X[x:x+1])
    return  y_test[x], scalerY.inverse_transform(pred)[0][0]</p>
<div class="highlight"><pre><span></span>scalerX = MinMaxScaler(feature_range=(0,1))
scalerY = MinMaxScaler(feature_range=(0,1))


scaled_training_X = scalerX.fit_transform(X_train)
scaled_testing_X = scalerX.fit_transform(X_test)


scaled_training_y = scalerY.fit_transform(y_train.reshape(-1, 1))
scaled_testing_y = scalerY.fit_transform(y_test.reshape(-1, 1))
</pre></div>
            <aside>
            <hr/>
            <nav>
            <ul class="articles_timeline">
 
                <li class="previous_article">« <a href="/stop_writing_classes.html" title="Previous: Thoughts on "Stop Writing Classes" PyCon 2012 talk">Thoughts on "Stop Writing Classes" PyCon 2012 talk</a></li>
 
                <li class="next_article"><a href="/get_data_into_redshift.html" title="Next: The easiest way to get data into Redshift">The easiest way to get data into Redshift</a> »</li>
            </ul>
            </nav>
            </aside>
        </div>
        <section>
        <div class="span2" style="float:right;font-size:0.9em;">
 
            <h4>Published</h4>
            <time pubdate="pubdate" datetime="2018-10-18T12:30:00-04:00">Oct 18, 2018</time>
 
            <h4>Last Updated</h4>
            <div class="last_updated">2018-10-18 12:30:00-04:00</div>
            <h4>Category</h4>
            <a class="category-link" href="/categories.html#Keras-ref">Keras</a> 
            <h4>Tags</h4>
            <ul class="list-of-tags tags-in-article"> 
                <li><a href="/tags.html#deep-learning-ref">deep learning
                    <span>1</span>
</a></li>
                <li><a href="/tags.html#keras-ref">keras
                    <span>1</span>
</a></li>
                <li><a href="/tags.html#neural-networks-ref">neural networks
                    <span>1</span>
</a></li>
                <li><a href="/tags.html#python-ref">python
                    <span>5</span>
</a></li>
            </ul>

        </div>
        </section>
</div>
</article>
                </div>
                <div class="span1"></div>
            </div>
        </div>
    </div>
<footer>
<div id="footer">
    <ul class="footer-content">
        <li class="elegant-power">Powered by <a href="http://getpelican.com/" title="Pelican Home Page">Pelican</a>. Theme: <a href="http://oncrashreboot.com/pelican-elegant" title="Theme Elegant Home Page">Elegant</a> by <a href="http://oncrashreboot.com" title="Talha Mansoor Home Page">Talha Mansoor</a></li>
    </ul>
</div>
</footer>            <script src="http://code.jquery.com/jquery.min.js"></script>
        <script src="//netdna.bootstrapcdn.com/twitter-bootstrap/2.3.1/js/bootstrap.min.js"></script>
        <script>
            function validateForm(query)
            {
                return (query.length > 0);
            }
        </script>

    </body>
</html>