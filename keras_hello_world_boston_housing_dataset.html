<!DOCTYPE html>
<html lang="en-US">
    <head>
        <meta charset="utf-8"> 
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <meta name="author" content="Sam Zuckerman" />
        <meta name="copyright" content="Sam Zuckerman" />

<meta name="keywords" content="python, deep learning, keras, neural networks, Keras, " />
        <title>Keras "Hello World" Example for Regression  Â· programming notes
</title>
        <link href="http://cdn-images.mailchimp.com/embedcode/slim-081711.css" rel="stylesheet" type="text/css">
        <link href="//netdna.bootstrapcdn.com/twitter-bootstrap/2.3.1/css/bootstrap-combined.min.css" rel="stylesheet">
        <link rel="stylesheet" type="text/css" href="https://szuckerman.github.io/theme/css/style.css" media="screen">
        <link rel="stylesheet" type="text/css" href="https://szuckerman.github.io/theme/css/solarizedlight.css" media="screen">
        <link rel="shortcut icon" href="https://szuckerman.github.io/theme/images/favicon.ico" type="image/x-icon" />
        <link rel="apple-touch-icon" href="https://szuckerman.github.io/theme/images/apple-touch-icon.png" />
        <link rel="apple-touch-icon" sizes="57x57" href="https://szuckerman.github.io/theme/images/apple-touch-icon-57x57.png" />
        <link rel="apple-touch-icon" sizes="72x72" href="https://szuckerman.github.io/theme/images/apple-touch-icon-72x72.png" />
        <link rel="apple-touch-icon" sizes="114x114" href="https://szuckerman.github.io/theme/images/apple-touch-icon-114x114.png" />
        <link rel="apple-touch-icon" sizes="144x144" href="https://szuckerman.github.io/theme/images/apple-touch-icon-144x144.png" />
        <link rel="icon" href="https://szuckerman.github.io/theme/images/apple-touch-icon-144x144.png" />
        <link href="https://szuckerman.github.io/feeds/all.atom.xml" type="application/atom+xml" rel="alternate" title="programming notes - Full Atom Feed" />
        <link href="https://szuckerman.github.io/feeds/Keras.atom.xml" type="application/atom+xml" rel="alternate" title="programming notes - Keras Category Atom Feed" />
        <link href="https://szuckerman.github.io/feeds/Python.atom.xml" type="application/atom+xml" rel="alternate" title="programming notes - Python Category Atom Feed" />
        <link href="https://szuckerman.github.io/feeds/R.atom.xml" type="application/atom+xml" rel="alternate" title="programming notes - R Category Atom Feed" />
        <link href="https://szuckerman.github.io/feeds/Redshift.atom.xml" type="application/atom+xml" rel="alternate" title="programming notes - Redshift Category Atom Feed" />
        <link href="https://szuckerman.github.io/feeds/S3.atom.xml" type="application/atom+xml" rel="alternate" title="programming notes - S3 Category Atom Feed" />
    <script type="text/javascript">
    var _gaq = _gaq || [];
    _gaq.push(['_setAccount', 'UA-128575468-1']);
    _gaq.push(['_trackPageview']);
    (function() {
        var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
        ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
        var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
    })();
    </script>
    </head>
    <body>
        <div id="content-sans-footer">
        <div class="navbar navbar-static-top">
            <div class="navbar-inner">
                <div class="container">
                    <a class="btn btn-navbar" data-toggle="collapse" data-target=".nav-collapse">
                        <span class="icon-bar"></span>
                        <span class="icon-bar"></span>
                        <span class="icon-bar"></span>
                    </a>
                    <a class="brand" href="https://szuckerman.github.io/"><span class=site-name>programming notes</span></a>
                    <div class="nav-collapse collapse">
                        <ul class="nav pull-right top-menu">
                            <!--<li ><a href="https://szuckerman.github.io">Home</a></li>-->
                            <li ><a href="https://szuckerman.github.io/categories.html">Categories</a></li>
                            <li ><a href="https://szuckerman.github.io/tags.html">Tags</a></li>
                            <li ><a href="https://szuckerman.github.io/archives.html">Archives</a></li>
                            <li><form class="navbar-search" action="https://szuckerman.github.io/search.html" onsubmit="return validateForm(this.elements['q'].value);"> <input type="text" class="search-query" placeholder="Search" name="q" id="tipue_search_input"></form></li>
                        </ul>
                    </div>
                </div>
            </div>
        </div>
        <div class="container-fluid">
            <div class="row-fluid">
                <div class="span1"></div>
                <div class="span10">
<article>
<div class="row-fluid">
    <header class="page_header span10 offset2">
    <h1><a href="https://szuckerman.github.io/keras_hello_world_boston_housing_dataset.html"> Keras "Hello World" Example for Regression  </a></h1>
    </header>
</div>

<div class="row-fluid">
        <div class="span8 offset2 article-content">

            <p>The following example uses the <a href="https://www.kaggle.com/c/boston-housing">Boston Housing dataset</a> to predict the median value of homes in a specific Boston suburb in 1978.</p>
<p>We're using this dataset since:
 1. It's well known
 2. It's included in Keras so you don't need to download any other dependencies.</p>
<h1>Getting Keras</h1>
<p>If you don't already have Keras and Scikit-Learn installed, you can download both using pip:</p>
<div class="highlight"><pre><span></span><span class="n">pip</span> <span class="n">install</span> <span class="n">keras</span>
<span class="n">pip</span> <span class="n">install</span> <span class="n">scikit</span><span class="o">-</span><span class="n">learn</span>
</pre></div>


<p>If you need additional help, you can check out <a href="https://keras.io/">the Keras documentation</a>. </p>
<h1>Loading Packages</h1>
<p>We're going to need the following:</p>
<div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">keras.datasets</span> <span class="kn">import</span> <span class="n">boston_housing</span>
<span class="kn">from</span> <span class="nn">keras.models</span> <span class="kn">import</span> <span class="n">Sequential</span>
<span class="kn">from</span> <span class="nn">keras.layers</span> <span class="kn">import</span> <span class="n">Dense</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">MinMaxScaler</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>

<span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">),</span> <span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span> <span class="o">=</span> <span class="n">boston_housing</span><span class="o">.</span><span class="n">load_data</span><span class="p">()</span>
</pre></div>


<p>Neural networks work best when the data is normalized. The network would get confused with our data when comparing small and big numbers of different units (like tax rates and non-business acres). </p>
<div class="highlight"><pre><span></span><span class="n">scalerX</span> <span class="o">=</span> <span class="n">MinMaxScaler</span><span class="p">(</span><span class="n">feature_range</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>
<span class="n">scalerY</span> <span class="o">=</span> <span class="n">MinMaxScaler</span><span class="p">(</span><span class="n">feature_range</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>

<span class="n">scaled_training_X</span> <span class="o">=</span> <span class="n">scalerX</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
<span class="n">scaled_testing_X</span> <span class="o">=</span> <span class="n">scalerX</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="n">scaled_training_y</span> <span class="o">=</span> <span class="n">scalerY</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">y_train</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
<span class="n">scaled_testing_y</span> <span class="o">=</span> <span class="n">scalerY</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">y_test</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
</pre></div>


<p>We're going to create a sequential neural network, dense layers and 32 nodes for each layer.</p>
<p>The two important parts in the following code block are <code>input_dim=13</code> and <code>Dense(1, activation='linear')</code>.</p>
<p>The <code>input_dim</code> maps to the number of columns in the dataset (we have 13 variables we're using to predict) and the last layer should have one node (hence, <code>Dense(1)</code>) to show that we're predicting one value.</p>
<div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="n">input_dim</span><span class="o">=</span><span class="mi">13</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;linear&#39;</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s1">&#39;mse&#39;</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="s1">&#39;adam&#39;</span><span class="p">)</span>
</pre></div>


<p>The above model has four layers with two hidden layers where each of the layers are dense. Dense means that every node in one layer maps to every node in the next layer. This way as information passes through the network it will make linear transformations of the data with information of 'lower importance' being pushed closer to zero.</p>
<p>We're basing our loss on MSE or <a href="https://en.wikipedia.org/wiki/Mean_squared_error">Mean Squared Error</a>, a standard regression loss metric (i.e. how 'off' was each prediction from the real value). We're also using the <a href="https://en.wikipedia.org/wiki/Stochastic_gradient_descent#Adam">ADAM optimizer</a> to update the network weights. The more finely tuned the network weights are, the better fit the model will be.</p>
<p>Also, there's discussion as to how many layers and nodes should be included in a network and choosing the right numbers is more of an art than a science. The above could have just as easily been:</p>
<div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="n">input_dim</span><span class="o">=</span><span class="mi">13</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;linear&#39;</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s1">&#39;mse&#39;</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="s1">&#39;adam&#39;</span><span class="p">)</span>
</pre></div>


<p>But with less nodes and layers, we risk underfitting the network.</p>
<h1>Fitting and Evaluating the Model</h1>
<p>Fitting a model in Keras is easy; just run the <code>fit</code> method:</p>
<div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">scaled_training_X</span><span class="p">,</span> <span class="n">scaled_training_y</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>


<p>An epoch is a "run" through the data to optimize the weights. We're choosing 100 epochs since it doesn't take that long to run and we need a good number of passes through the data to allow the optimizer to update the weights accordingly. </p>
<p>Here's the output since we had <code>verbose</code> set to <code>1</code> (showing the first 10 and last 10 epochs):</p>
<div class="highlight"><pre><span></span>Epoch 1/100
404/404 [==============================] - 0s 47us/step - loss: 0.0358
Epoch 2/100
404/404 [==============================] - 0s 48us/step - loss: 0.0188
Epoch 3/100
404/404 [==============================] - 0s 47us/step - loss: 0.0159
Epoch 4/100
404/404 [==============================] - 0s 40us/step - loss: 0.0139
Epoch 5/100
404/404 [==============================] - 0s 43us/step - loss: 0.0125
Epoch 6/100
404/404 [==============================] - 0s 51us/step - loss: 0.0113
Epoch 7/100
404/404 [==============================] - 0s 32us/step - loss: 0.0105
Epoch 8/100
404/404 [==============================] - 0s 40us/step - loss: 0.0099
Epoch 9/100
404/404 [==============================] - 0s 49us/step - loss: 0.0095
Epoch 10/100
404/404 [==============================] - 0s 36us/step - loss: 0.0090
...
Epoch 90/100
404/404 [==============================] - 0s 52us/step - loss: 0.0040
Epoch 91/100
404/404 [==============================] - 0s 48us/step - loss: 0.0041
Epoch 92/100
404/404 [==============================] - 0s 48us/step - loss: 0.0040
Epoch 93/100
404/404 [==============================] - 0s 52us/step - loss: 0.0040
Epoch 94/100
404/404 [==============================] - 0s 31us/step - loss: 0.0040
Epoch 95/100
404/404 [==============================] - 0s 42us/step - loss: 0.0040
Epoch 96/100
404/404 [==============================] - 0s 48us/step - loss: 0.0041
Epoch 97/100
404/404 [==============================] - 0s 38us/step - loss: 0.0040
Epoch 98/100
404/404 [==============================] - 0s 49us/step - loss: 0.0039
Epoch 99/100
404/404 [==============================] - 0s 49us/step - loss: 0.0039
Epoch 100/100
404/404 [==============================] - 0s 34us/step - loss: 0.0039
</pre></div>


<p>And to evaluate:    </p>
<div class="highlight"><pre><span></span><span class="n">mse</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">scaled_testing_X</span><span class="p">,</span> <span class="n">scaled_testing_y</span><span class="p">)</span>
</pre></div>


<p>Since we used mse as a loss function above, when we use the <code>evaluate</code> method, we'll get mse returned.</p>
<blockquote>
<p>Note: We are evaluating with the test data and will also be predicting with the test data as well. Usually when preparing a model for production one has a breakdown of training, testing and validation data sets for model evaluation. We are merely using the testing data to show how the model performs on unseen data.  </p>
</blockquote>
<p>Output:</p>
<div class="highlight"><pre><span></span><span class="o">&gt;&gt;&gt;</span> <span class="mf">0.017321763085383995</span>
</pre></div>


<p><strong>Note:</strong> you might get different slightly results based on rounding issues .</p>
<h1>So What Does This Mean?</h1>
<p>Since we have the MSE, we want to know how "off" our predictions are. A quick explanation to MSE is that you take all your predictions, subtract the real values, square each result, and add those all together.</p>
<h2>Why do we square the values?</h2>
<p>The following shows why we square the values:</p>
<p>Let's say we have three data points: [1, 2, 3]
Let's say we have three predicted points: [3, 2, 1]</p>
<p>We would have the following total (without squaring):</p>
<div class="highlight"><pre><span></span><span class="mi">1</span><span class="o">-</span><span class="mi">4</span> <span class="o">=</span> <span class="o">-</span><span class="mi">3</span>
<span class="mi">2</span><span class="o">-</span><span class="mi">2</span> <span class="o">=</span>  <span class="mi">0</span>
<span class="mi">5</span><span class="o">-</span><span class="mi">1</span> <span class="o">=</span>  <span class="mi">4</span>


<span class="o">-</span><span class="mi">3</span> <span class="o">+</span> <span class="mi">0</span> <span class="o">+</span> <span class="mi">4</span> <span class="o">=</span> <span class="mi">1</span>
</pre></div>


<p>This would, incorrectly, imply a near-perfect model.</p>
<p>Now, with squaring:</p>
<div class="highlight"><pre><span></span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="mi">4</span><span class="p">)</span><span class="o">^</span><span class="mi">2</span> <span class="o">=</span> <span class="mi">9</span>
<span class="p">(</span><span class="mi">2</span><span class="o">-</span><span class="mi">2</span><span class="p">)</span><span class="o">^</span><span class="mi">2</span> <span class="o">=</span> <span class="mi">0</span>
<span class="p">(</span><span class="mi">5</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">^</span><span class="mi">2</span> <span class="o">=</span> <span class="mi">16</span>

<span class="mi">9</span> <span class="o">+</span> <span class="mi">0</span> <span class="o">+</span> <span class="mi">16</span> <span class="o">=</span> <span class="mi">25</span>
</pre></div>


<p>Basically, by squaring we take care of the positive/negative number issue.</p>
<p>Sometimes it's useful to take the square-root of the Mean Square Error so we'll get the same units that we're predicting (in this case dollars). In the above example we would see that our predictions were 'off' by 5 over the testing data.</p>
<p>In Python we could calculate this by:</p>
<div class="highlight"><pre><span></span><span class="n">rmse</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">mse</span><span class="p">)</span>
</pre></div>


<p>It's not so necessary in this case to take the Root Mean Square Error, though, since we scaled the data (i.e. an RMSE of 2345 wouldn't relate to $2345) and a main reason for these loss models is to compare models to eachother; the number by itself isn't very useful.</p>
<h1>Comparing Keras Regression model to Linear Model</h1>
<p>First we need to import the proper libraries:</p>
<div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LinearRegression</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">mean_squared_error</span>
 <span class="sb">``</span><span class="err">`</span>

 <span class="sb">``</span><span class="err">`</span><span class="n">python</span>
<span class="n">boston_linear_model</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">()</span>

<span class="n">boston_linear_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">scaled_training_X</span><span class="p">,</span> <span class="n">scaled_training_y</span><span class="p">)</span>

<span class="n">y_pred</span> <span class="o">=</span> <span class="n">boston_linear_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">scaled_testing_X</span><span class="p">)</span>

<span class="n">mean_squared_error</span><span class="p">(</span><span class="n">scaled_testing_y</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
</pre></div>


<div class="highlight"><pre><span></span><span class="o">&gt;&gt;&gt;</span> <span class="mf">0.018737306901733503</span>
</pre></div>


<div class="highlight"><pre><span></span>scalerX = MinMaxScaler(feature_range=(0,1))
scalerY = MinMaxScaler(feature_range=(0,1))


scaled_training_X = scalerX.fit_transform(X_train)
scaled_testing_X = scalerX.fit_transform(X_test)


scaled_training_y = scalerY.fit_transform(y_train.reshape(-1, 1))
scaled_testing_y = scalerY.fit_transform(y_test.reshape(-1, 1))
</pre></div>
<section>
<div class="accordion" id="accordion2">
    <div class="accordion-group">
        <div class="accordion-heading">
            <a class="accordion-toggle disqus-comment-count" data-toggle="collapse" data-parent="#accordion2"
                href="https://szuckerman.github.io/keras_hello_world_boston_housing_dataset.html#disqus_thread">
                Comments
            </a>
        </div>
        <div id="disqus_thread" class="accordion-body collapse">
            <div class="accordion-inner">
                <div class="comments">
<div id="disqus_thread"></div>
<script type="text/javascript">
    var disqus_shortname = 'szuckerman-github-io-1';
        var disqus_identifier = 'https://szuckerman.github.io/keras_hello_world_boston_housing_dataset.html';
    var disqus_url = 'https://szuckerman.github.io/keras_hello_world_boston_housing_dataset.html';

    (function() {
         var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
         dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
         (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
     })();
</script>
<noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="http://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>                </div>
            </div>
        </div>
    </div>
</div>
</section>
            <aside>
            <hr/>
            <nav>
            <ul class="articles_timeline">
 
                <li class="previous_article">Â« <a href="https://szuckerman.github.io/stop_writing_classes.html" title="Previous: Thoughts on "Stop Writing Classes" PyCon 2012 talk">Thoughts on "Stop Writing Classes" PyCon 2012 talk</a></li>
 
                <li class="next_article"><a href="https://szuckerman.github.io/get_data_into_redshift.html" title="Next: The easiest way to get data into Redshift">The easiest way to get data into Redshift</a> Â»</li>
            </ul>
            </nav>
            </aside>
        </div>
        <section>
        <div class="span2" style="float:right;font-size:0.9em;">
 
            <h4>Published</h4>
            <time pubdate="pubdate" datetime="2018-10-18T12:30:00-04:00">Oct 18, 2018</time>
 
            <h4>Last Updated</h4>
            <div class="last_updated">2018-10-18 12:30:00-04:00</div>
            <h4>Category</h4>
            <a class="category-link" href="/categories.html#Keras-ref">Keras</a> 
            <h4>Tags</h4>
            <ul class="list-of-tags tags-in-article"> 
                <li><a href="/tags.html#deep-learning-ref">deep learning
                    <span>1</span>
</a></li>
                <li><a href="/tags.html#keras-ref">keras
                    <span>1</span>
</a></li>
                <li><a href="/tags.html#neural-networks-ref">neural networks
                    <span>1</span>
</a></li>
                <li><a href="/tags.html#python-ref">python
                    <span>8</span>
</a></li>
            </ul>

        </div>
        </section>
</div>
</article>
                </div>
                <div class="span1"></div>
            </div>
        </div>
    </div>
<footer>
<div id="footer">
    <ul class="footer-content">
        <li class="elegant-power">Powered by <a href="http://getpelican.com/" title="Pelican Home Page">Pelican</a>. Theme: <a href="http://oncrashreboot.com/pelican-elegant" title="Theme Elegant Home Page">Elegant</a> by <a href="http://oncrashreboot.com" title="Talha Mansoor Home Page">Talha Mansoor</a></li>
    </ul>
</div>
</footer>            <script src="http://code.jquery.com/jquery.min.js"></script>
        <script src="//netdna.bootstrapcdn.com/twitter-bootstrap/2.3.1/js/bootstrap.min.js"></script>
        <script>
            function validateForm(query)
            {
                return (query.length > 0);
            }
        </script>

<script type="text/javascript">
    var disqus_shortname = 'szuckerman-github-io-1';

    (function () {
        var s = document.createElement('script'); s.async = true;
        s.type = 'text/javascript';
        s.src = '//' + disqus_shortname + '.disqus.com/count.js';
        (document.getElementsByTagName('HEAD')[0] || document.getElementsByTagName('BODY')[0]).appendChild(s);
    }());
    </script>
        <script  language="javascript" type="text/javascript">
            function uncollapse() {
                var hash_str = window.location.hash;
                if (window.location.hash.match(/^#comment-\d+$/))
                {
                    var hash_str = '#disqus_thread';
                }
                $(hash_str).collapse({
                    toggle: true
                    })
            }
        </script>

        <script type="text/javascript" language="JavaScript">
            uncollapse(); 
        </script>
    </body>
</html>